# -*- coding: utf-8 -*-
"""compare_mirror.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E-fBiHDiXYEP7VeGBNgG2ddITTg8SxwM
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
base_dir = root_dir + 'Individual_reward_networks/'
import os
import sys
sys.path.append(base_dir)
os.chdir(base_dir)

from matplotlib import pyplot as plt
from torch.utils.data import Dataset as Dataset
import numpy as np
import pickle
from network_evaluation_functions import evaluate_network2, get_entropy, get_entropy_per_layer, difference_evaluation2
from matplotlib import pyplot as plt
from network_evaluation_functions import graph_connections
import pandas as pd
from mutation_network import mutation_networks
from sparse_mirror_network import mirror_network
from one_v_all_function import one_vs_all_data
from all_versus_1_MNIST import transform_data
# from one_v_all_function import X_train_one, X_test_one, y_train_one, y_test_one
train_size = 60000
MNIST_data = pd.read_csv('TSNE_all_untouched')
MNIST_train = MNIST_data[:train_size]
MNIST_test = MNIST_data[train_size:]

def one_hot(n):
    n = int(n)
    vec = [0] * 10
    vec[n] = 1
    return vec


class MNIST_set(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, item):
        X_p = self.X[item]
        y_p = self.y[item]
        return X_p, y_p

#
# train_dataset = MNIST_set(X_train_one, y_train_one)
# val_dataset = MNIST_set(X_test_one, y_test_one)

my_mirror_network = mirror_network(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

def train_model_initialise(network, learning_rate, num_epochs, mutation_rate, dataset, val_dataset):
    entropies = []
    layer_entropies = []
    validation_scores = []
    training_scores = []
    for epoch in range(num_epochs):
        epoch_accuracy = 0
        entropies.append(get_entropy(network))
        layer_entropies.append(get_entropy_per_layer(network))
        validation_scores.append(evaluate_network2(network, val_dataset))
        print('Epoch: ', epoch)
        print('Entropy: ', entropies[-1])
        print('Validation Score: ', validation_scores[-1])
        if entropies[-1] < 0.05:
            break
        for id, data in enumerate(dataset):
            X, y = data
            output, strategies, _ = network.forward(X)
            y = np.asarray(y)
            output = np.asarray(output)
            comparison = output == y
            if comparison.all():
                epoch_accuracy += 1
                error = 0
            else:
                error = 1

            fitness = 1 - error
            "update according to fitness"
            if fitness != 0:
                update = (1 - (learning_rate * fitness))
                for i in range(network.num_layers):
                    for j in range(network.neurons_in_each_layer[i]):
                        neuron = network.neuron_list[i][j]
                        chosen_strategy = strategies[i][j]
                        neuron.mixed_strategy = [update * item for item in neuron.mixed_strategy]
                        neuron.mixed_strategy[chosen_strategy] += (learning_rate * fitness)
                        neuron.mixed_strategy = [item / sum(neuron.mixed_strategy) for item in neuron.mixed_strategy]
            "update according to mutation"
            if mutation_rate != 0:
                for i in range(network.num_layers):
                    for j in range(network.neurons_in_each_layer[i]):
                        neuron = network.neuron_list[i][j]
                        n = neuron.num_strategies
                        neuron.mixed_strategy = [((1 - mutation_rate) * item) + ((1-item) * mutation_rate/n) for item in
                                                 neuron.mixed_strategy]
                        neuron.mixed_strategy = [item / sum(neuron.mixed_strategy) for item in neuron.mixed_strategy]
        training_scores.append(epoch_accuracy / len(dataset))
        print('Training Scores: ', training_scores[-1])

    columns = []
    for i in range(network.num_layers):
        j = i+1
        columns.append('Layer ' + str(j))
    layer_dataframe = pd.DataFrame(layer_entropies, columns=columns)
    plt.figure()
    layer_dataframe.plot()

    #plt.plot(entropies)
    plt.xlabel("Epoch")
    plt.ylabel("Mean Entropy")
    plt.title("MR: " + str(mutation_rate) + " LR:" + str(learning_rate))
    plt.grid(True)
    plt.show()

    plt.plot(training_scores)
    plt.xlabel("Epoch")
    plt.ylabel("Training Accuracy")
    plt.title("MR: " + str(mutation_rate) + " LR:" + str(learning_rate) + str(network))
    plt.grid(True)
    plt.show()

    plt.plot(validation_scores)
    plt.xlabel("Epoch")
    plt.ylabel("Validation Accuracy")
    plt.title("MR: " + str(mutation_rate) + " LR:" + str(learning_rate) + str(network))
    plt.grid(True)
    plt.show()
    return validation_scores, training_scores, layer_entropies



#graph_connections(my_network)
# train_model_initialise(my_mirror_network, 0.001, 60, 0, train_dataset, val_dataset)

network_zero = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_one = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_two = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_three = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_four = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_five = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_six = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_seven = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_eight = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])

network_nine = mutation_networks(neurons_in_each_layer=[9, 9, 6, 3, 1],
                               connections_in_each_layer=[3, 3, 3, 3, 3],
                               input_size=[9])



classifier_validation_scores = []
classifier_train_scores = []
classifier_layer_entropies = []
mixed_strategies_all = []

my_classifiers = [network_zero, network_one, network_two, network_three, network_four, network_five,
                  network_six, network_seven, network_eight, network_nine]


with open('mirror_strats', 'rb') as f:
    strats = pickle.load(f)


for i in range(10):
    network = my_classifiers[i]
    network.load_mixed_strategy(strats[i])
    dataframe = one_vs_all_data(MNIST_train, i)
    dataframe_val = one_vs_all_data(MNIST_test, i)
    X_train, y_train = transform_data(dataframe)
    X_val, y_val = transform_data(dataframe_val)
    train_dataset = MNIST_set(X_train, y_train)
    val_dataset = MNIST_set(X_val, y_val)
    print('Val Score:', evaluate_network2(network, val_dataset)

# val_scores, train_scores, layer_entropies = train_model_initialise(network, 0.001, 30, 0, train_dataset, val_dataset)
# classifier_validation_scores.append(val_scores)
# classifier_train_scores.append(train_scores)
# classifier_layer_entropies.append(layer_entropies)
# mixed_strategies_all.append(network.save_mixed_strategy())


# import pickle
# with open('normal_train_40+30.pkl', 'wb') as f:
#     pickle.dump(classifier_train_scores, f)
    
# with open('normal_val_40+30.pkl', 'wb') as f:
#     pickle.dump(classifier_validation_scores, f)
    
# with open('normal_strat_40+30.pkl', 'wb') as f:
#     pickle.dump(mixed_strategies_all, f)
    
# with open('normal_entropy_40+30.pkl', 'wb') as f:
# pickle.dump(classifier_layer_entropies, f)